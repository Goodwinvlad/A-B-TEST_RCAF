{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B testing: RCAF function 20221001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном notebook отдел качества сети комании российского оператора проводит A/B test, формулируется гипотеза, тестируется, и проводится финальное интепритация результата. Предоставленные данные собранны с коммерческой сети оператора, которые содержат результаты A/B test группы без применения нового функционала и группы с раскатаным функционалом (without_RCAF vs. with_RCAF). \n",
    "\n",
    "Что собираемся делать:\n",
    "\n",
    "1. [Дизайн эксперимента](#1.-Дизайн-эксперимента)\n",
    "2. [Сбор и подготовка данных](#2.-Сбор-и-подготовка-данных)\n",
    "3. [Представление результатов](#3.-Представление-результатов)\n",
    "4. [Тестирование гипотезы](#4.-Тестирование-гипотезы)\n",
    "5. [Итоги теста](#5.-Итоги-теста)\n",
    "\n",
    "Описание функционала:\n",
    "\n",
    "> Данный функционал разработан с целью увеличения скорости абонентов на высокозагруженных сотах в часы пик. Функционал определяет приоритеты абонентов и устанавливает правила ограничения по скорости на сервисы для низкоприоритетных и назначает освобожденные ресурсы для высокоприоритетных абонентов. Для тестирования выбран город в Южном регионе РФ, определены соты и часы с высокой утилизацией. Абонент попадает в группу тестирования только с правилом, что высокоутилизированная сота для него со статусом 'любимая' (самая часто используемая). Средняя скорость для отображения видео сервиса с примелемым качеством равняется 3Mbps. Мы знаем, что текущий коэффициент конверсии составляет около 15% в среднем в данном регионе. Это значит что **15% абонентов на перегруженных сотах имеют скорость более 3Mbps**. Компания ожидает получить профит при увеличении на 3%, это означает, что **новый функционал будет считаться успешным, если он повысит коэффициент конверсии до 18%.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Дизайн эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формулирование гипотезы\n",
    "\n",
    "Сформулируем гипотезу в начале нашего проекта. Это позволит убедиться, что наша интерпретация результатов будет правильной.\n",
    "\n",
    "Поскольку мы не знаем, будет ли новый функционал работать лучше или хуже (или так же?), как наш текущий режим, мы выберем **two-tailed test**:\n",
    "\n",
    "$$H_0: p = p_0$$\n",
    "$$H_a: p \\ne p_0$$\n",
    "\n",
    "где $p$ и $p_0$ обозначают коэффициент конверсии функциона и старого режима соответственно. Так же установим **confidence level of 95%**:\n",
    "\n",
    "$$\\alpha = 0.05$$\n",
    "\n",
    "Значение $\\alpha$ — это порог, который мы устанавливаем, при котором мы говорим: «Если вероятность наблюдения результата как экстремального или более (значение $p$) ниже, чем $\\alpha$, то мы отвергаем нулевую гипотезу». . Поскольку наш $\\alpha=0,05$ (что указывает на вероятность 5%), наша confidence level (1 - $\\alpha$) составляет 95%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор переменных\n",
    "\n",
    "Для начала выберем **две группы**:\n",
    "* A `control` group - исполльзуется старый режим сети\n",
    "* A `treatment` (наша экспериментная) группа - для которой будет расскатан новый функционал\n",
    "\n",
    "Это будет наша *Независимая переменная*. Причина, по которой у нас есть две группы, несмотря на то, что мы знаем базовый коэффициент конверсии, заключается в том, что мы хотим контролировать другие переменные, которые могут повлиять на наши результаты, такие как сезонность и аварии на сети: имея «контрольную» группу, мы можем напрямую сравнивать их результаты с группой «тестовой», потому что единственное систематическое различие между группами заключается в новом функционале.\n",
    "\n",
    "Для нашей *зависимой переменной* (т.е. то, что мы пытаемся измерить) нас интересует \"коэффициент конверсии\". Мы можем закодировать это для каждого сеанса пользователя с помощью двоичной переменной:\n",
    "* `0` - абонент со скоростью ниже 3Mbps на перегруженной соте\n",
    "* `1` - абонент со скоростью выше 3Mbps на перегруженной соте\n",
    "\n",
    "Таким образом, мы можем легко рассчитать среднее значение для каждой группы, чтобы получить коэффициент конверсии для каждого режима."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор размера сэмпла\n",
    "\n",
    "Важно отметить, что поскольку мы не будем тестировать всю абонентскую базу.\n",
    "\n",
    "Количество людей , которые мы решим включить в каждую группу, повлияет на точность наших оценочных коэффициентов конверсии: **чем больше размер выборки**, **тем выше шанс обнаружить разницу** в двух группах, если она присутствует.\n",
    "\n",
    "С другой стороны, чем больше становится наша выборка, тем дороже становится наше исследование.\n",
    "\n",
    "Необходимый нам размер выборки оценивается с помощью анализа мощности, и это зависит от нескольких факторов:\n",
    "* **Мощность теста** ($1 - \\beta$) - это вероятность обнаружения статистической разницы между группами в нашем тесте, когда разница действительно присутствует. Как правило, это значение равно 0,8\n",
    "* **Альфа-значение** ($\\alpha$) — критическое значение, которое мы установили ранее равным 0,05.\n",
    "* **Величина эффекта** – ожидаемая разница между коэффициентами конверсии.\n",
    "\n",
    "Поскольку нашу команду устроила бы разница в 3 %, мы можем использовать 15 % и 18 % для расчета ожидаемой величины эффекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# plot styling preferences\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "font = {'family' : 'Helvetica',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size = sms.proportion_effectsize(0.15, 0.18)    # Расчет размера эффекта \n",
    "\n",
    "required_n = sms.NormalIndPower().solve_power(\n",
    "    effect_size, \n",
    "    power=0.8, \n",
    "    alpha=0.02, \n",
    "    ratio=1\n",
    "    )                                                  # расчет размера выборки\n",
    "\n",
    "required_n = ceil(required_n)                          # округление до следующего целого числа                          \n",
    "\n",
    "print(required_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам потребуется **не менее 3067 наблюдений для каждой группы**.\n",
    "\n",
    "Установка параметра «мощность» на 0,8 на практике означает, что если существует фактическая разница в коэффициенте конверсии между нашими дизайнами, при условии, что разница является той, которую мы оценили (15% против 18%), у нас есть около 80% шансов на успех обнаружить его как статистически значимое в нашем тесте с рассчитанным нами размером выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Набор данных мы берем CoreNetwork статистики по каждому абоненту\n",
    "2. Прочитаем данные в pandas DataFrame\n",
    "3. Проверим и очистим данные по мере необходимости.\n",
    "4. Минимальный размер выборки n=3067 из DataFrame для каждой группы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ab_data_1.csv', sep = ';')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В DataFrame **294478 строк**, каждая из которых представляет сеанс пользователя, а также **5 столбцов**:\n",
    "* `user_id` - идентификатор пользователя каждой сессии\n",
    "* `timestamp` - отметка времени сеанса\n",
    "* `group` — к какой группе был отнесен пользователь для этого сеанса {`control`, `treatment`}\n",
    "* `mode` — какой дизайн видел каждый пользователь в этом сеансе {`old_page`, `new_page`}\n",
    "* `speed` - закончился ли сеанс конверсией или нет (двоичный, `0`=ниже 3Mbps, `1`=выше 3Mbps)\n",
    "\n",
    "Прежде чем мы приступим к выборке данных для получения нашего подмножества, давайте удостоверимся, что нет пользователей, которые были отобраны несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_counts = df['user_id'].value_counts(ascending=False)\n",
    "multi_users = session_counts[session_counts > 1].count()\n",
    "\n",
    "print(f'{multi_users} users которые появляются несколько раз в наборе данных')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле есть пользователи, которые появляются более одного раза. Поскольку число довольно низкое, мы продолжим и удалим их из DataFrame, чтобы избежать повторной выборки одних и тех же пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_to_drop = session_counts[session_counts > 1].index\n",
    "\n",
    "df = df[~df['user_id'].isin(users_to_drop)]\n",
    "print(f'Обновленный набор данных теперь имеет {df.shape[0]} записей')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выборка\n",
    "\n",
    "Теперь, когда наш DataFrame в порядке, можем продолжить и отобрать n=3067 записей для каждой из групп. Для этого мы можем использовать метод DataFrame.sample() от pandas, который выполнит для нас простую случайную выборку.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_sample = df[df['group'] == 'control'].sample(n=required_n, random_state=25)\n",
    "treatment_sample = df[df['group'] == 'treatment'].sample(n=required_n, random_state=25)\n",
    "\n",
    "ab_test = pd.concat([control_sample, treatment_sample], axis=0)\n",
    "ab_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Представление результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое, что мы можем сделать, это рассчитать некоторые **базовые статистические данные**, чтобы получить представление о том, как выглядят наши выборки.\n",
    "\n",
    "Напомню:\n",
    "Стандартное отклонение измеряет, насколько разбросаны значения в наборе данных. Стандартная ошибка — это стандартное отклонение среднего значения в повторных выборках из совокупности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rates = ab_test.groupby('group')['speed']\n",
    "\n",
    "std_p = lambda x: np.std(x)              # Std. deviation Стандартное отклонение\n",
    "se_p = lambda x: stats.sem(x)            # Std. error of the proportion (std / sqrt(n)) стандартная ошибка среднего\n",
    "\n",
    "conversion_rates = conversion_rates.agg([np.mean, std_p, se_p])\n",
    "conversion_rates.columns = ['conversion_rate', 'std_deviation', 'std_error']\n",
    "\n",
    "\n",
    "conversion_rates.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по приведенной выше статистике, похоже, что новый функционал работает лучше, **Коэффициент конверсии 15,3% против 18,7%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.barplot(x=ab_test['group'], y=ab_test['speed'], ci=False)\n",
    "\n",
    "plt.ylim(0, 0.17)\n",
    "plt.title('Conversion rate by group', pad=20)\n",
    "plt.xlabel('Group', labelpad=15)\n",
    "plt.ylabel('Converted (proportion)', labelpad=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Является ли эта разница статистически значимой?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. Тестирование гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последним шагом нашего анализа является проверка нашей гипотезы. Так как у нас очень большая выборка, мы можем использовать  normal approximation для расчета нашего значения $p$ (т.е. z-тест).\n",
    "\n",
    "Мы будем использовать модуль `statsmodels.stats.proportion`, чтобы получить значение $p$ и доверительные интервалы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_results = ab_test[ab_test['group'] == 'control']['speed']\n",
    "treatment_results = ab_test[ab_test['group'] == 'treatment']['speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_con = control_results.count()\n",
    "n_treat = treatment_results.count()\n",
    "successes = [control_results.sum(), treatment_results.sum()]\n",
    "nobs = [n_con, n_treat]\n",
    "\n",
    "z_stat, pval = proportions_ztest(successes, nobs=nobs)\n",
    "(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n",
    "\n",
    "print(f'z statistic: {z_stat:.2f}')\n",
    "print(f'p-value: {pval:.3f}')\n",
    "print(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\n",
    "print(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. Итоги теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наше значение $p$ на много ниже значения $\\alpha$=0,05, мы можем отвергнуть нулевую гипотезу $H_0$, а это означает, что наш функционал имеет существенные отличия от нашего старого режима.\n",
    "\n",
    "Кроме того, если мы посмотрим на доверительный интервал для «тестовой» группы ([0.173, 0.201], то есть 18,5-18,9%), то заметим, что:\n",
    "1. Он не включает наше базовое значение коэффициента конверсии 15%.\n",
    "2. Он включает наше целевое значение в 18 % (3 % роста, к которому мы стремились).\n",
    "\n",
    "Это еще одно доказательство того, что наш новый функционал будет улучшением нашего старого режима работы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
